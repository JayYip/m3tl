# AUTOGENERATED! DO NOT EDIT! File to edit: source_nbs/14_run_bert_multitask.ipynb (unless otherwise specified).

__all__ = ['create_keras_model', 'get_params_ready', 'train_bert_multitask', 'create_tensorspec_from_shape_type',
           'trim_checkpoint_for_prediction', 'eval_bert_multitask', 'predict_bert_multitask']

# Cell
import json
import os
import time
from shutil import copytree, ignore_patterns, rmtree
from typing import Callable, Dict, List, Tuple, Union

from sklearn.preprocessing import MultiLabelBinarizer
from transformers import PreTrainedTokenizer

import tensorflow as tf
from loguru import logger
from .input_fn import predict_input_fn, train_eval_input_fn
from .model_fn import BertMultiTask
from .params import Params
from .special_tokens import EVAL, PREDICT
from .utils import (compress_tf_warnings, get_or_make_label_encoder,
                        infer_shape_and_type_from_dict, set_phase, LabelEncoder, get_is_pyspark)
from tensorflow.python.framework.errors_impl import \
    NotFoundError as TFNotFoundError

compress_tf_warnings()
# Fix duplicate log
# LOGGER = tf.get_logger()
# LOGGER.propagate = False


# Cell
def create_keras_model(
        mirrored_strategy: tf.distribute.MirroredStrategy,
        params: Params,
        mode='train',
        inputs_to_build_model=None,
        model=None,
        run_eagerly=False):

    def _get_model_wrapper(params, mode, inputs_to_build_model, model):
        # Horovod: Specify `experimental_run_tf_function=False` to ensure TensorFlow
        # uses hvd.DistributedOptimizer() to compute gradients.
        experimental_run_tf_function = not params.use_horovod
        if model is None:
            model = BertMultiTask(params)
            # model.run_eagerly = True
        set_phase(PREDICT)
        if mode == 'resume':
            model.compile(run_eagerly=run_eagerly,
                          experimental_run_tf_function=experimental_run_tf_function)
            # build training graph
            # model.train_step(inputs_to_build_model)

            _ = model(inputs_to_build_model)
            # load ALL vars including optimizers' states
            try:
                model.load_weights(os.path.join(
                    params.ckpt_dir, 'model'), skip_mismatch=False)
            except TFNotFoundError:
                logger.warning('Not resuming since no mathcing ckpt found')
        elif mode == 'transfer':
            # build graph without optimizers' states
            # calling compile again should reset optimizers' states but we're playing safe here
            _ = model(inputs_to_build_model)
            # load weights without loading optimizers' vars
            model.load_weights(os.path.join(params.init_checkpoint, 'model'))
            # compile again
            model.compile(run_eagerly=run_eagerly,
                          experimental_run_tf_function=experimental_run_tf_function)
        elif mode == 'predict':
            _ = model(inputs_to_build_model)
            # load weights without loading optimizers' vars
            model.load_weights(os.path.join(params.ckpt_dir, 'model'))
        elif mode == 'eval':
            _ = model(inputs_to_build_model)
            # load weights without loading optimizers' vars
            model.load_weights(os.path.join(params.ckpt_dir, 'model'))
            model.compile(run_eagerly=run_eagerly,
                          experimental_run_tf_function=experimental_run_tf_function)
        else:
            model.compile(run_eagerly=run_eagerly,
                          experimental_run_tf_function=experimental_run_tf_function)

        return model
    if mirrored_strategy is not None:
        with mirrored_strategy.scope():
            model = _get_model_wrapper(
                params, mode, inputs_to_build_model, model)
    else:
        model = _get_model_wrapper(params, mode, inputs_to_build_model, model)
    return model


# Cell
def _has_callbacks(callbacks: List[tf.keras.callbacks.Callback], check_callback: tf.keras.callbacks.Callback) -> bool:
    for callback in callbacks:
        if isinstance(callback, check_callback):
            return True
    return False


def _train_bert_multitask_keras_model(train_dataset: tf.data.Dataset,
                                      eval_dataset: tf.data.Dataset,
                                      model: tf.keras.Model,
                                      params: Params,
                                      mirrored_strategy: tf.distribute.MirroredStrategy = None,
                                      callbacks: List[tf.keras.callbacks.Callback] = None,
                                      verbose=1):

    all_callbacks = params.gather_mtl_callbacks()

    if callbacks is not None:
        all_callbacks += callbacks

    # if callbacks is not passed or callbacks dose not contain
    # ModelCheckpoint and TensorBoard callbacks, we add the default ones

    # can't save whole model with model subclassing api due to tf bug
    # see: https://github.com/tensorflow/tensorflow/issues/42741
    # https://github.com/tensorflow/tensorflow/issues/40366
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath=os.path.join(params.ckpt_dir, 'model'),
        save_weights_only=True,
        monitor='val_mean_acc',
        mode='auto',
        save_best_only=False)

    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=params.ckpt_dir)

    has_model_checkpoint_callback = _has_callbacks(
        all_callbacks, tf.keras.callbacks.ModelCheckpoint)

    # horovod callbacks
    if params.use_horovod:
        import horovod.tensorflow.keras as hvd
        # when using horovod as dist backend, only save model in process 0
        if not has_model_checkpoint_callback:
            if hvd.rank() == 0:
                all_callbacks.append(model_checkpoint_callback)
        all_callbacks = [
            hvd.callbacks.BroadcastGlobalVariablesCallback(0),
            hvd.callbacks.MetricAverageCallback()
        ] + all_callbacks
        # Horovod: write logs on worker 0.
        verbose = verbose if hvd.rank() == 0 else 0
    elif not has_model_checkpoint_callback:
        all_callbacks.append(model_checkpoint_callback)

    validation_steps = params.get('validation_steps', 1000)

    if mirrored_strategy is not None:
        with mirrored_strategy.scope():
            model.fit(
                x=train_dataset,
                validation_data=eval_dataset,
                epochs=params.train_epoch,
                callbacks=all_callbacks,
                steps_per_epoch=params.train_steps_per_epoch,
                verbose=verbose,
                validation_steps=validation_steps
            )
    else:
        model.fit(
            x=train_dataset,
            validation_data=eval_dataset,
            epochs=params.train_epoch,
            callbacks=all_callbacks,
            steps_per_epoch=params.train_steps_per_epoch,
            verbose=verbose,
            validation_steps=validation_steps
        )
    model.summary()


# Cell
def get_params_ready(problem, num_gpus, model_dir, params, problem_type_dict, processing_fn_dict, mode='train', json_path='') -> Params:
    if params is None:
        params = Params()
    if not os.path.exists('models'):
        os.mkdir('models')
    if model_dir:
        base_dir, dir_name = os.path.split(model_dir)
    else:
        base_dir, dir_name = None, None
    # add new problem to params if problem_type_dict and processing_fn_dict provided
    if problem_type_dict:
        params.register_multiple_problems(
            problem_type_dict=problem_type_dict, processing_fn_dict=processing_fn_dict)

    if not params.problem_assigned and not problem:
        raise ValueError('neither params problem assigned nor problem provided.')

    if mode == 'train':
        if problem:
            params.assign_problem(problem, model_dir=model_dir)
        params.to_json()
    else:
        params.from_json(json_path)
        if problem:
            params.assign_problem(problem, model_dir=model_dir, predicting=True)

    return params


# Cell
# @logger.catch
def train_bert_multitask(
        problem='weibo_ner',
        num_gpus=1,
        num_epochs=10,
        model_dir='',
        params: Params = None,
        problem_type_dict: Dict[str, str] = None,
        processing_fn_dict: Dict[str, Callable] = None,
        model: tf.keras.Model = None,
        create_tf_record_only=False,
        steps_per_epoch: int = None,
        warmup_ratio=0.1,
        continue_training=False,
        mirrored_strategy: tf.distribute.MirroredStrategy = None,
        run_eagerly=False,
        callbacks: List[tf.keras.callbacks.Callback] = None,
        verbose=1) -> tf.keras.Model:
    """
    Train Multi-task Bert model

    Keyword Arguments:
    - problem (str, optional) -- Problems to train. Defaults to 'weibo_ner'
    - num_gpus (int, optional) -- Number of GPU to use. Defaults to 1
    - num_epochs (int, optional) -- Number of epochs to train. Defaults to 10
    - model_dir (str, optional) -- model dir. Defaults to ''
    - params (Params, optional) -- Params to define training and models. Defaults to None
    - problem_type_dict (dict, optional) -- Key: problem name, value: problem type. Defaults to None
    - processing_fn_dict (dict, optional) -- Key: problem name, value: problem data preprocessing fn. Defaults to None
    - model (tf.keras.Model, optional): if not provided, it will be created using `create_keras_model`. Defaults to None.
    - create_tf_record_only (bool, optional): if `True`, the function will only create TFRecord without training model. Defaults to False.
    - steps_per_epoch (int, optional): steps per epochs, if not provided, train datset will be looped once to calculate steps per epoch. Defaults to None.
    - warmup_ratio (float, optional): lr warmup ratio. Defaults to 0.1.
    - continue_training (bool, optional): whether to resume training from `model_dir`. Defaults to False.
    - mirrored_strategy (MirroredStrategy, optional): Tensorflow MirroredStrategy. Defaults to None.
    - run_eagerly (bool, optional): Whether to run model eagerly. Defaults to False.
    - callbacks (list, optional): list of callbacks to add during training. If None, ModelCheckpoint will be added.
    - verbose (int, optional): 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. Note that the progress bar is not particularly useful when logged to a file, so verbose=2 is recommended when not running interactively (eg, in a production environment).
    """
    if params is None:
        params = Params()
    if params.use_horovod:
        import horovod.tensorflow.keras as hvd
        hvd.init()
        gpus = tf.config.experimental.list_physical_devices('GPU')
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        if gpus:
            tf.config.experimental.set_visible_devices(
                gpus[hvd.local_rank()], 'GPU')

    params = get_params_ready(problem, num_gpus, model_dir,
                              params, problem_type_dict, processing_fn_dict)
    params.train_epoch = num_epochs

    train_dataset = train_eval_input_fn(params)
    eval_dataset = train_eval_input_fn(params, mode=EVAL)
    if create_tf_record_only:
        return

    if get_is_pyspark():
        raise NotImplementedError(
            'Pyspark only support creating TFRecord. Please set create_tf_record_only as True when pyspark is enabled.')

    # get train_steps and update params
    if steps_per_epoch is not None:
        train_steps = steps_per_epoch
    else:
        train_steps = 0
        for _ in train_dataset:
            train_steps += 1
    params.update_train_steps(train_steps, warmup_ratio=warmup_ratio)

    train_dataset = train_eval_input_fn(params)
    train_dataset = train_dataset.repeat()

    one_batch = next(train_dataset.as_numpy_iterator())

    if mirrored_strategy is None:
        mirrored_strategy = tf.distribute.MirroredStrategy()
    elif mirrored_strategy is False:
        mirrored_strategy = None

    if num_gpus > 1 and mirrored_strategy is not False:
        train_dataset = mirrored_strategy.experimental_distribute_dataset(
            train_dataset)
        eval_dataset = mirrored_strategy.experimental_distribute_dataset(
            eval_dataset)

    # restore priority: self > transfer > huggingface
    if continue_training and tf.train.latest_checkpoint(params.ckpt_dir):
        mode = 'resume'
    elif tf.train.latest_checkpoint(params.init_checkpoint):
        mode = 'transfer'
    else:
        mode = 'train'

    if model is None:
        model = create_keras_model(
            mirrored_strategy=mirrored_strategy, params=params,
            mode=mode, inputs_to_build_model=one_batch,
            run_eagerly=run_eagerly)

    _train_bert_multitask_keras_model(
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        model=model,
        params=params,
        mirrored_strategy=mirrored_strategy,
        callbacks=callbacks,
        verbose=verbose
    )
    params.to_json()
    return model


# Cell
def create_tensorspec_from_shape_type(infered_shape_and_type: Tuple[Dict[str, list], Dict[str, tf.dtypes.DType]]) -> Dict[str, tf.TensorSpec]:

    shape_dict, type_dict = infered_shape_and_type
    tensorspec_dict = {}
    for name in shape_dict.keys():
        tensorspec_dict[name] = tf.TensorSpec(shape=[None for _ in shape_dict[name]], dtype=type_dict[name], name=name)
    return tensorspec_dict

# Cell
@logger.catch
def trim_checkpoint_for_prediction(problem: str,
                                   input_dir: str,
                                   output_dir: str,
                                   problem_type_dict: Dict[str, str] = None,
                                   overwrite=True,
                                   fake_input_list=None,
                                   params=None,
                                   save_weights_only=True):

    if overwrite and os.path.exists(output_dir):
        rmtree(output_dir)
    copytree(input_dir, output_dir, ignore=ignore_patterns(
        'checkpoint', '*.index', '*.data-000*'))
    base_dir, dir_name = os.path.split(output_dir)
    if params is None:
        params = Params()

    if problem_type_dict:
        params.register_multiple_problems(problem_type_dict=problem_type_dict)
    params.from_json(os.path.join(input_dir, 'params.json'))
    params.assign_problem(problem, base_dir=base_dir,
                          dir_name=dir_name, predicting=True)

    model = BertMultiTask(params)
    if fake_input_list is None:
        dummy_dataset = predict_input_fn(['fake']*5, params)
    else:
        dummy_dataset = predict_input_fn(fake_input_list*5, params)

    batch_fake_data = next(dummy_dataset.as_numpy_iterator())
    shape_type_dict = infer_shape_and_type_from_dict(batch_fake_data)
    spec_dict = create_tensorspec_from_shape_type(infered_shape_and_type=shape_type_dict)

    # _ = model(batch_fake_data,
    #           mode=tf.estimator.ModeKeys.PREDICT)
    # monkeypatch predict_step
    # model.call = MethodType(tf.function(lambda x, y: model.call(x, mode=PREDICT)), model)
    set_phase(PREDICT)
    _ = model(batch_fake_data)
    model.load_weights(os.path.join(input_dir, 'model'))
    logger.critical("serving input sigantures: {}".format(spec_dict))
    if save_weights_only:
        model.save_weights(os.path.join(params.ckpt_dir, 'model'))
    else:
        class ServingModule(tf.Module):
            def __init__(self):
                super(ServingModule, self).__init__()
                self.model = model

            @tf.function
            def serve(self, x):
                return self.model.call(x)
        serving_module = ServingModule()
        _ = serving_module.serve(batch_fake_data)
        signatures = dict(
            serving_default=serving_module.serve.get_concrete_function(spec_dict)
        )
        tf.saved_model.save(serving_module, os.path.join(params.ckpt_dir, 'serving'), signatures=signatures)
    params.to_json()


# Cell
@logger.catch
def eval_bert_multitask(
        problem='weibo_ner',
        num_gpus=1,
        model_dir='',
        params=None,
        problem_type_dict=None,
        processing_fn_dict=None,
        model=None,
        run_eagerly=False):

    if not model_dir and params is not None:
        model_dir = params.ckpt_dir
    params = get_params_ready(problem, num_gpus, model_dir,
                              params, problem_type_dict, processing_fn_dict,
                              mode='predict', json_path=os.path.join(model_dir, 'params.json'))
    eval_dataset = train_eval_input_fn(params, mode=EVAL)
    one_batch_data = next(eval_dataset.as_numpy_iterator())
    eval_dataset = train_eval_input_fn(params, mode=EVAL)
    mirrored_strategy = tf.distribute.MirroredStrategy()
    if model is None:
        model = create_keras_model(
            mirrored_strategy=mirrored_strategy, params=params,
            mode='eval', inputs_to_build_model=one_batch_data, run_eagerly=run_eagerly)
    eval_dict = model.evaluate(eval_dataset, return_dict=True)
    return eval_dict


# Cell
@logger.catch
def predict_bert_multitask(
        inputs,
        problem='weibo_ner',
        model_dir='',
        params: Params = None,
        problem_type_dict: Dict[str, str] = None,
        processing_fn_dict: Dict[str, Callable] = None,
        model: tf.keras.Model = None,
        return_model=False,
        run_eagerly=False,
        mirrored_strategy=None,
        decode_prediction=False):
    """Use Multi-task Bert model to do prediction

        Args:
        - inputs (Iterable): Iterable of inputs
        - problem (str, optional): problems to predict. Defaults to 'weibo_ner'.
        - model_dir (str, optional): model dir. Defaults to ''.
        - params (Params, optional): params. Defaults to None.
        - problem_type_dict (Dict[str, str], optional): Key: problem name, value: problem type.. Defaults to None.
        - processing_fn_dict (Dict[str, Callable], optional): Key: problem name, value: problem data preprocessing fn. Defaults to None.
        - model (tf.keras.Model, optional): If not provided, it will be created with `create_keras_model`. Defaults to None.
        - return_model (bool, optional): Whether return model, if True, function will return (pred, model) tuple. Defaults to False.
        - run_eagerly (bool, optional): Whether to run model eagerly. Defaults to False.
        - mirrored_strategy (optional): mirrored strategy for distribute prediction. Defaults to None.
        - decode_prediction (bool, optional): whether to decode predictions. Defaults to False.
    """
    set_phase(PREDICT)
    if params is None:
        params = Params()
    if not model_dir and params is not None:
        model_dir = params.ckpt_dir
    params = get_params_ready(problem, 1, model_dir,
                              params, problem_type_dict, processing_fn_dict,
                              mode='predict', json_path=os.path.join(model_dir, 'params.json'))

    logger.info('Checkpoint dir: {}'.format(params.ckpt_dir))
    time.sleep(3)

    pred_dataset = predict_input_fn(inputs, params)
    one_batch_data = next(pred_dataset.as_numpy_iterator())
    pred_dataset = predict_input_fn(inputs, params)

    if model is None:
        model = create_keras_model(
            mirrored_strategy=mirrored_strategy, params=params,
            mode='predict', inputs_to_build_model=one_batch_data,
            run_eagerly=run_eagerly)

    if mirrored_strategy is not None:
        with mirrored_strategy.scope():
            pred = model.predict(pred_dataset)
    else:
        pred = model.predict(pred_dataset)

    if decode_prediction:
        pred = decode_predictions(pred=pred, params=model.params)

    if return_model:
        return pred, model
    return pred
